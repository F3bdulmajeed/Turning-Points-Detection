library(Rcpp)
library(Rfast)
library(zoo)
sourceCpp("algorithms/cpp_functions.cpp")
sourceCpp("algorithms/algo.cpp")




adjust_range <- function(h){
  return( (h+pi)%%(2*pi)-pi)
}


# 
# CosineSegment <- function(h , a , b , c , I , tau ) {
#   
#   # A representation of a simple cosine and its range 
#   
#   # This is a representation of the likelihood function as a function of mu .. conditioned on the last turning points is tau.
#   # This function can be written as Σcos(h_t - mu)  + c = a*sin(mu) + b*cos(mu) + c = R cos(mu - alpha)
#   # a = Σ sin(h_t) , b = Σ cos(h_t) , c is just a constant , alpha is the mean heading and R is the mean resultant length
#   # "I" represent the interval of this cosines wave I is a subset if (-pi , pi]
#   
#   
#   R <- 1   
#   max_value <- 1 + c
#   double_pi <- 2*pi
#   alpha <- h
#   a <- a
#   b <- b
#   c <- c
#   I <- I
#   tau <- tau
#   RANGE <- matrix(c(-pi , pi ), nc =2)
#   D <-  RANGE
#   
#   
#   # Update the likelihood with new observation
#   update <- function(new_a , new_b){
#     a <<- a + new_a 
#     b <<- b + new_b 
#     R <<- sqrt(a^2 + b^2)
#     max_value <<- R + c
#     
#   }
#   
#   
#   # Find the roots of solving max(Rcos(mu-a) + c, z)
#   roots = function(z) {
#     
#     
#     
#     dis <- (z - c) / R
#     # No real solutions
#     if (dis >= 1) {
#       return(NULL)
#     }
#     
#     # The whole space is solution 
#     if ( dis <= -1) {
#       return(I)
#     }
#     
#     
#     alpha <<- atan2(a, b)
#     lhs <-    acos(dis)
#     lower <- (-lhs + alpha + pi) %% double_pi - pi
#     upper <- (lhs + alpha + pi) %% double_pi - pi
#     
#     solution_range <- if (lower > upper) {
#       matrix(c(-pi, upper, lower, pi), ncol = 2, byrow = TRUE)
#     } else {
#       matrix(c(lower, upper), ncol = 2, byrow = TRUE)
#     }
#     
#     I <<- calculateIntercepts(solution_range, I)
#     
#     return(I)
#   }
#   
# 
#   
#   environment()
# }
# 
# 
# 
# 
# AFPOP = function(h, penalty){
#   sinh = sin(h)
#   cosh <- cos(h)
#   n <- length(h)
#   RANGE <- matrix(c(-pi,pi), nc= 2)
#   D = RANGE 
#   likelihood_list = c(CosineSegment(h = h[1]  , a = sinh[1] , b= cosh[1]  , c = penalty , I = D, tau =1))
#   last_tps = numeric(length = n)
#   t=2
#   
#   while(t<=n){ # looping through the data and applying FPOP 
#     new_obs_s = sinh[t]
#     new_obs_c = cosh[t]
#     obs = h[t]
#     
#     
#     maximum = -Inf
#     tau = NA
#     for(seg in likelihood_list){
#       max_value = seg$max_value
#       if(max_value > maximum){
#         maximum = max_value
#         tau = seg$tau
#       }
#     }
#     
#     
#     last_tps[t] <- tau
#     maximum <- maximum+penalty  
# 
#     new_likelihood_list = c()
#     
#     union = c()
#     
#     for(seg in likelihood_list){
#       root = seg$roots(maximum)
#       if(length(root)>0){
#         if(length(union)==0){
#           union = root
#         }else{
#           union = calculateUnion( union, root )
#         }
#         
#         seg$update(new_a = new_obs_s, new_b = new_obs_c)
#         new_likelihood_list = c(new_likelihood_list ,seg)
#       }
#     }
#     
#     new_range = calculateDifference(union)
#     new_seg = CosineSegment(a= new_obs_s , b = new_obs_c , c = maximum , h = obs, I = new_range , tau = t)
#     likelihood_list =c(new_likelihood_list,  new_seg)
#     t = t+1
#     
#     
#   }
#   
# 
#   # looping backwards through last_tps to find the turning points  
#   tps = c(n)
#   last = n
#   while (last > 1){
#     last = last_tps[last] -1 
#     tps = c(tps, last)
#   }
#   tps = sort(tps)
#   
#   print(last_tps)
#   return(tps)
#   
# }
# 


D_AFPOP <- function(h , rho , penalty , d_level , c = NULL ) {
  
  q = rho/(1-rho)
  n = length(h)
  mu <- seq(-pi,pi,  length = 360/d_level )
  cos_h <- cos(h) ; sin_h <- sin(h) ; cos_mu<- cos(mu) ; sin_mu<- sin(mu)
  Msine <- Outer(sin_h , sin_mu , "*")
  Mcosine <- Outer(cos_h , cos_mu , "*")
  D <- cos(diff(h))
  M <-  Msine + Mcosine
  if(!is.null(c)){
    M <- pmax(M,c)
  }
  if(q != 0){
    M <- compute_descratised_space(M,D,q)
  }
  likelihood_curve <- M[,1]
  range <- rep(1,  360/d_level )
  maximum <- max(likelihood_curve) + penalty
  last_tps <- numeric(n-1)
  last_tps[1] = 0
  t = 2
  while(t <= (n-1)){
    which_less  <- likelihood_curve <= maximum
    if(any(which_less)){
      range[which_less] <- t+1
      likelihood_curve[which_less] <-  maximum}
    likelihood_curve <-  likelihood_curve  +  M[,t]
    
    argmax <-  which.max(likelihood_curve)
    last_tps[t] <- range[argmax]
    maximum = likelihood_curve[argmax] + penalty
    t= t+1
  }
  tps <- c(n)
  last = n-1
  # Decoding the set of turning-points and mean headings. 
  while (last > 1){
    last = last_tps[last-1] - 1
    tps <- c(tps, last)
  }
  tps = sort(tps)
  return(tps)
}




APELT <- function(h, penalty, rho) {
  
  n = length(h)
  sh <-  sin(h)
  ch <-  cos(h)
  
  cumsum_sh <- cumsum(sh)
  cumsum_ch <- cumsum(ch)
  cosdf <- cos(diff(h))
  
  Fs <- numeric(n)
  Fs[1] = -(penalty + 1)
  not_pruned <- c(1)
  tps <- vector("list", length = n)
  q <- rho / (1 - rho)
  qq <- 1 + q^2
  q2 <- 2 * q
  
  for (s in 2:n) {
    min_value <- numeric(length(not_pruned))
    arg_min_value <- integer(length(not_pruned))
    
    for (i in seq_along(not_pruned)) {
      tau <- not_pruned[i]
      sn <- s - tau
      mean_sh <- (cumsum_sh[s] - cumsum_sh[tau]) / sn
      mean_ch <- (cumsum_ch[s] - cumsum_ch[tau]) / sn
      
      seg <- tau:s
      seg_sh <- sh[seg]
      seg_ch <- ch[seg]
      
      tcos <- mean_ch * seg_ch + mean_sh * seg_sh
      top <- tcos[-1] + q * cosdf[seg[-1] - 1]
      bot <- sqrt(qq + q2 * tcos[-sn])
      cost <- Fs[tau] - sum(top / bot) + penalty
      
      min_value[i] <- cost
    }
    
    wm <- which.min(min_value)
    Fs[s] <- min_value[wm]
    last_tp <- not_pruned[wm]
    tps[[s]] <- c(tps[[last_tp]], last_tp)
    
    not_pruned <- c(not_pruned[Fs[s] + penalty > min_value], s)
  }
  TPS = c(tps[[s]],n)
  TPS[1]=0
  TPS
}



robust_params_estimation  <- function(h , max_rho) {
  h <- na.omit(h)
  d1 <- adjust_range(diff(h,1))
  d2 <- adjust_range(diff(h,2))
  md1 <- atan2( median(sin(d1)), median(cos(d1)))
  md2 <- atan2( median(sin(d2)), median(cos(d2)))
  d1 <- adjust_range(d1 - md1)
  d2 <- adjust_range(d2 - md2)
  sd1 <- sin(d1)
  cd1 <- cos(d1)
  cd2 <- cos(d2)
  n <-  length(sd1)
  med_cd1 <-  median(  (1-cd1)  ) 
  med_cd2 <-  median(  (1-cd2)  ) 
  rho    <-    min( med_cd2/med_cd1 - 1 , max_rho )
  dewhitened_h <- d1[-1] - atan2(rho*sd1[-n] ,1-rho + rho*cd1[-n])
  kappa_rho <- 1/(2.19*median(1-cos(dewhitened_h)) )
  rho_mu <-  kappa_rho*(1-rho^2)
  return(c(rho , kappa_rho, rho_mu))
}



unrobust_params_estimation  <- function(h) {
  h <- na.omit(h)
  d1 <- adjust_range(diff(h,1))
  sd1 <- sin(d1)
  cd1 <- cos(d1)
  n <- length(sd1)
  med_cd1 <-  sum(  sd1[-1]*sd1[-n]  ) 
  med_cd2 <-  sum(  sd1[-1]^2 ) + sum( sd1[-n]^2  ) 
  rho    <-   2*(med_cd1/med_cd2) + 1
  dewhitened_h <- adjust_range( d1[-1] - atan2(rho*sd1[-n] ,1-rho + rho*cd1[-n]) )
  kappa_rho <-  Rfast::vm.mle(dewhitened_h)$param[2]
  rho_mu <-  kappa_rho*(1-rho^2)
  return(c(rho , kappa_rho, rho_mu))
}



nonparam_estimation  <- function(h, window, align) {
  s <- sin(h)
  c <- cos(h)
  ms <- zoo::rollmedian(s, window , na.pad = TRUE , align = align)
  mc <- zoo::rollmedian(c, window , na.pad = TRUE , align = align)
  med_head <- atan2(ms, mc)
  errors   <- na.omit( adjust_range(  h - med_head  ) )
  sin_errors <- sin(errors)
  cos_errors <- cos(errors)
  n <- length(sin_errors)
  rho <-  sum( sin_errors[-1]*sin_errors[-n] ) / sqrt(   sum( sin_errors[-1]^2 ) * sum( sin_errors[-n]^2 ) )
  whitened_h <- adjust_range( errors[-1] - atan2(rho*sin_errors[-n] ,1- rho + rho*cos_errors[-n]) )
  kappa_rho <-  circular::mle.vonmises(circular::circular( whitened_h ) )
  rho_mu <-  circular::mle.vonmises(circular::circular( errors ) )
  return(c(rho , kappa_rho$kappa , rho_mu$kappa))
}



calculate_expected_headings <- function(h , tps ,rho){
  q <- rho/(1-rho)
  diffh <- cos(diff(h))
  end.vec = tps[-1]
  change.vec <- end.vec[-length(end.vec)]
  start.vec <- c(1,change.vec+1)
  seg.mean <- numeric(length = length(h))
  for(seg.i in seq_along(start.vec)){
    start <- start.vec[seg.i]
    end <- end.vec[seg.i]
    seg.data <- h[start:end]
    seg.mean[start:end]  <- rep(  CircStats::circ.mean(seg.data) , length(seg.data)  )
  }
  h_prev <- h[-length(h)]
  mu_new<- seg.mean[-1]
  expec <- atan2(
    sin(mu_new) + q*sin(h_prev),
    cos(mu_new) + q*cos(h_prev)
  )
  expec <- (expec+pi)%%(2*pi)-pi
  expec
}



calculate_expected_main_headings <- function(h , tps){
  diffh <- cos(diff(h))
  end.vec = tps[-1]
  change.vec <- end.vec[-length(end.vec)]
  start.vec <- c(1,change.vec+1)
  seg.mean <- numeric(length = length(h))
  for(seg.i in seq_along(start.vec)){
    start <- start.vec[seg.i]
    end <- end.vec[seg.i]
    seg.data <- h[start:end]
    seg.mean[start:end]  <- rep(  CircStats::circ.mean(seg.data) , length(seg.data)  )
  }
  seg.mean
}


find_bearing <- function(x,y){

  n  = length(x)
  bearing = atan2( y[-1] - y[-n] , x[-1] - x[-n] )
  
}



calculate_sigma <- function(x,y,tp){
  m = length(tp) 
  fitted_x = c()
  fitted_y = c()
  for(i in 2:m){
    seg = (tp[i-1]+1):(tp[i])
    X0 =  x[tp[i-1] +1]
    X1 =  x[tp[i]]
    Y0 = y[tp[i-1]  +1]
    Y1 = y[tp[i]]
    mx = X0 + ((seg-tp[i-1])/(tp[i] - tp[i-1])) * (X1 - X0)
    my = Y0 + ((seg-tp[i-1])/(tp[i] - tp[i-1])) * (Y1 - Y0)
    fitted_x = c(fitted_x ,  mx  )
    fitted_y = c(fitted_y ,  my  )
  }
  distances <- sqrt( (x-fitted_x)^2 +   (y-fitted_y)^2 )
  rss <-  sqrt(var(distances))
  mn <- mean(diff(tp))
  output = list("rss" = rss/mn , "fitted_x" = fitted_x , "fitted_y" = fitted_y, "distances"= distances)
  return(output)
}



iterative_estimation <- function(h ,  model , itr_max, k = 40 ){
  if(!model %in% c("AR", "IID")){stop("Model Is Unkown")}
  n <- length(h)
  kappa <-  1/(2.19*median(1-cos(diff(h,k))) )
  C <-   -2*log(n)/kappa
  
  tps <- D_AFPOP(h , 0 , C , 1/2)
  TPS <- list(tps)
  
  if(model == "AR"){
    for(j in 2:itr_max){
      exp <- calculate_expected_main_headings(h , tps)
      errors <-  (h - exp +pi)%%(2*pi)-pi
      sin_errors <- sin(errors)
      rho <-  sum(sin_errors[-n]*sin_errors[-1])/sum(sin_errors^2)
      dewhited_mean <- calculate_expected_headings(h , tps , rho)
      dewhited_errors <-  (h[-1] - dewhited_mean +pi)%%(2*pi)-pi
      kappa <- Rfast::vm.mle(dewhited_errors)$param[2]
      penalty <- C/kappa
      tps <- D_AFPOP(h , rho , penalty  , 1/2)
      TPS[[j]] <- tps
      is_in_list <- any(sapply(TPS, identical, tps))
      if(is_in_list){break}
    }
    list("tps" = tps , "rho" = rho , "kappa"  = kappa)
    
  }else{
    for(j in 2:itr_max){
      exp <- calculate_expected_main_headings(h , tps)
      errors <-  (h - exp +pi)%%(2*pi)-pi
      kappa <- Rfast::vm.mle(errors)$param[2]
      penalty <- C/kappa 
      tps <- D_AFPOP(h , 0 , penalty  , 1/2)
      TPS[[j]] <- tps
      is_in_list <- any(sapply(TPS, identical, tps))
      if(is_in_list){break}
      
    }
    list("tps" = tps , "rho" = 0 , "kappa"  = kappa)
    
  }
}



iidseg_estimation <- function( h  , rho_max , d_level = 0.5 ){
  n <- length(h)
  C <- -2*log(n)
  details <- robust_params_estimation(h, rho_max)
  kappa <- details[3]
  rho <-  max( 0 , details[1])
  penalty <-  C/kappa   * (1+rho)/(1-rho)
  tps <- AFPOP(sin(h), cos(h), penalty)
  sort(tps)
  
}




iidseg_robust_estimation <- function( h  , rho_max , d_level = 0.5  , z = 0.01){
  n <- length(h)
  C <- -2*log(n)
  details <- robust_params_estimation(h, rho_max)
  
  kappa <- details[3]
  rho <-  max( 0 , details[1])
  penalty <-  C/kappa   * (1+rho)/(1-rho)
  
  alpha <- circular::pvonmises(z , circular::circular(0), kappa)
  tps <- D_AFPOP(h , 0 , penalty , d_level , c= abs(alpha))
  tps
  
}




ar1seg_estimation <- function( h  , rho_max , d_level = 0.5 ){
  n <- length(h)
  C <- -2*log(n)
  details <- robust_params_estimation(h, rho_max)
  kappa <- details[2]
  rho <-  max( 0 , details[1])
  penalty <-  C/kappa    
  tps <- D_AFPOP(h , rho , penalty , d_level)
  tps
  
}




filter_small_steps <- function(x, y, step) {
  step <- step^2
  n <- length(x)
  index <- integer(n)
  index[1] <- 1
  k <- 1
  i = 1 ; j =1
  while(j < n){
    for(j in (i+1):n){
      dis <- (x[i] - x[j])^2 + (y[i] - y[j])^2
      
      if (dis > step) {
        k <- k + 1
        index[k] <- j
        i = j
        break
      }
    }
  }
  
  return(index[1:k])
}






# A  Function to simulate a mean trajectory 
simulate_trajectory <- function(rate , n , min_ta){
  m <- rpois(1 , n*rate)
  taus <-  c(0 , sort(sample(1:n , m)) , n)
  samples <- numeric()  
  current_sample <- runif(1, -pi*3/2, pi*3/2)  
  while(length(samples) < (m+1)) { 
    new_sample <- runif(1, -pi, pi)
    if (abs(new_sample - current_sample) >= min_ta) {
      samples <- c(samples, new_sample)
      current_sample <- new_sample
    }
  }
  
  mu = rep(samples , diff(taus))
  return(list("mu"= mu , "taus"=taus))
}




# Given the real path a function for adding noise on it
simulate_path <- function(mu , kappa , rho ,  seed  = NULL , dis = "VM"){
  q = rho/(1-rho)
  n = length(mu)
  if(is.null(seed)){seed = runif(1, 0 , 1000000000000)}
  set.seed(seed)
  kappa_len <- length(kappa)

  if(kappa_len == 1   & dis == "VM"){
  noise <-  Rfast::rvonmises(n , 0 , kappa)
  }
  if(kappa_len != 1   & dis == "VM"){
    if(kappa_len != n){
      stop("kappa length not equal to ")
    }
    noise <- sapply(kappa, function(kappa) {
      Rfast::rvonmises(1, 0, kappa)
    })
  }
  
  
  if(dis == "WC"){
    noise <-  CircStats::rwrpcauchy(n , location = 0 , rho = kappa)
  }
  
  if(dis == "WN"){
    noise <-  CircStats::rwrpnorm(n , mu = 0 , rho = kappa)
  }
  
  
  sinmu <- sin(mu)
  cosmu <- cos(mu)
  h <- AR_simulator(noise, sinmu, cosmu, q, noise[1] + mu[1])
  h <- (h+pi)%%(2*pi) - pi
  return( h )
}




simulate_path_ARm <- function(mu , kappa, rho , params, seed = NULL){
  n = length(mu)
  lag <- length(params)
  if(is.null(seed)){seed = runif(1, 0 , 1000000000000)}
  set.seed(seed)
  kappa_len <- length(kappa)
  
  if(kappa_len == 1){
    noise <-  Rfast::rvonmises(n , 0 , kappa)
  }else{
    if(kappa_len != n){
      stop("kappa length not equal to ")
    }
    noise <- sapply(kappa, function(kappa) {
      Rfast::rvonmises(1, 0, kappa)
    })
  }
  
  sinmu <- (1-rho)*sin(mu)
  cosmu <- (1-rho)*cos(mu)
  
  h = numeric(n)
  s = numeric(n)
  c = numeric(n)
  h[1:lag] <- mu[1:lag] + noise[1:lag]
  s[1:lag] <- sin(h[1:lag])
  c[1:lag] <- cos(h[1:lag])
  
  
  
  for(t in (lag+1):n){
    seg <- ((t-lag):(t-1))
    
    sin_seg <- rho*sum(s[seg]*params)
    cos_seg <- rho*sum(c[seg]*params)
    
    est = noise[t] + atan2(sinmu[t] + sin_seg, 
                           cosmu[t] + cos_seg)
    
    h[t] = est
    s[t] = sin(est)
    c[t] = cos(est)
  }
  h <- (h+pi)%%(2*pi) - pi
  return( h )
}




potts_algo <- function(headings , window_size , thresh){
  cosines <- cos(headings)
  sines <- sin(headings)
  x_vals <- cumsum(cosines)
  y_vals <- cumsum(sines)
  
  # Find average cos and sin over sliding window, as well as 
  # squared circular standard deviations (SCSD)
  sd_length <- length(cosines) - window_size
  ave_cos_array <- cosines[1:sd_length]/window_size
  ave_sin_array <- sines[1:sd_length]/window_size
  for(counter in 1:(window_size-1))
  {
    # Shift cosine and sin arrays back by 1
    cosines <- cosines[-1]
    sines <- sines[-1]
    ave_cos_array <- ave_cos_array + cosines[1:sd_length]/window_size
    ave_sin_array <- ave_sin_array + sines[1:sd_length]/window_size
  }
  circ_sd <- (-2)*log(sqrt((ave_sin_array)^2 + (ave_cos_array)^2))
  ave_circ_sd <- sum(circ_sd) / length(circ_sd)
  
  # Find candidate turning points by looking for spikes in SCSD
  turning <- 0
  chgpt_array <- c(1)
  for(counter in 1:length(circ_sd))
  {
    if((circ_sd[counter] > ave_circ_sd)&(turning == 0))
    {
      # Started turning.  Note turning point
      start_chgpt <- counter 
      turning <- 1
    }
    if((circ_sd[counter] < ave_circ_sd)&(turning == 1))
    {
      # Turning point is the mean of the start turning-point and the end shifted to the right by resolution/2 
      # to account for averaging being done forwards in time
      chgpt <- floor((start_chgpt + counter)/2 + window_size/2)
      chgpt_array <- c(chgpt_array,chgpt)
      turning <- 0
    }
  }
  chgpt_array <- c(chgpt_array, length(cosines))
  
  # Post processing of changepoints to remove any where the switch in direction is less than thresh_angle
  new_chgpt_array <- vector(mode="numeric", length=0)
  prev_heading <- atan2(y_vals[chgpt_array[2]]-y_vals[chgpt_array[1]],
                        x_vals[chgpt_array[2]]-x_vals[chgpt_array[1]])
  for(counter in 2:(length(chgpt_array)-1))
  {
    next_heading <- atan2(y_vals[chgpt_array[counter+1]]-y_vals[chgpt_array[counter]],
                          x_vals[chgpt_array[counter+1]]-x_vals[chgpt_array[counter]])                              
    if(abs(next_heading - prev_heading) > pi)
    {
      turn_angle <- pi*2-abs(next_heading - prev_heading)
    }
    else
    {
      turn_angle <- abs(next_heading - prev_heading)
    }
    if(turn_angle*180/pi > thresh)
    {
      new_chgpt_array <- c(new_chgpt_array, chgpt_array[counter])
      prev_heading = next_heading  
    }
  }
  
  return( c(0,new_chgpt_array, length(headings)) )
}

